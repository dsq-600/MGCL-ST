{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1894632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsq_env/lib/python3.8/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn import metrics\n",
    "import multiprocessing as mp\n",
    "from MGCL import MGCL\n",
    "import os,csv,re, time\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.sparse import issparse\n",
    "import scanpy as sc\n",
    "import matplotlib.colors as clr\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import ST as ST\n",
    "from IPython.display import Image\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "n_clusters = 7\n",
    "dataset = '151673'\n",
    "\n",
    "adata = sc.read(\"/home/dingsq/dsq/MGCL-project/Data/151673/sample_data.h5ad\")\n",
    "adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c33382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-scale-new graph constructed!\n",
      "Begin to train ST data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:41<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished for ST data!\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = MGCL.MGCL(adata, device=device, alpha=6)\n",
    "\n",
    "# train model\n",
    "adata = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41d89d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching resolution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsq_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolution=1.0899999999999996, cluster number=10\n",
      "resolution=1.0799999999999996, cluster number=10\n",
      "resolution=1.0699999999999996, cluster number=10\n",
      "resolution=1.0599999999999996, cluster number=10\n",
      "resolution=1.0499999999999996, cluster number=10\n",
      "resolution=1.0399999999999996, cluster number=10\n",
      "resolution=1.0299999999999996, cluster number=10\n",
      "resolution=1.0199999999999996, cluster number=10\n",
      "resolution=1.0099999999999996, cluster number=10\n",
      "resolution=0.9999999999999996, cluster number=10\n",
      "resolution=0.9899999999999995, cluster number=10\n",
      "resolution=0.9799999999999995, cluster number=9\n",
      "resolution=0.9699999999999995, cluster number=9\n",
      "resolution=0.9599999999999995, cluster number=10\n",
      "resolution=0.9499999999999995, cluster number=9\n",
      "resolution=0.9399999999999996, cluster number=10\n",
      "resolution=0.9299999999999996, cluster number=10\n",
      "resolution=0.9199999999999996, cluster number=10\n",
      "resolution=0.9099999999999996, cluster number=10\n",
      "resolution=0.8999999999999996, cluster number=9\n",
      "resolution=0.8899999999999996, cluster number=10\n",
      "resolution=0.8799999999999996, cluster number=9\n",
      "resolution=0.8699999999999996, cluster number=9\n",
      "resolution=0.8599999999999995, cluster number=9\n",
      "resolution=0.8499999999999996, cluster number=8\n",
      "resolution=0.8399999999999996, cluster number=9\n",
      "resolution=0.8299999999999996, cluster number=9\n",
      "resolution=0.8199999999999996, cluster number=8\n",
      "resolution=0.8099999999999996, cluster number=8\n",
      "resolution=0.7999999999999996, cluster number=9\n",
      "resolution=0.7899999999999996, cluster number=8\n",
      "resolution=0.7799999999999997, cluster number=8\n",
      "resolution=0.7699999999999997, cluster number=8\n",
      "resolution=0.7599999999999997, cluster number=7\n"
     ]
    }
   ],
   "source": [
    "radius = 50\n",
    "\n",
    "tool = 'leiden' # mclust, leiden, and louvain\n",
    "\n",
    "# clustering\n",
    "from MGCL.utils import clustering\n",
    "\n",
    "if tool == 'mclust':\n",
    "   clustering(adata, n_clusters, radius=radius, method=tool, refinement=True) # For DLPFC dataset, we use optional refinement step.\n",
    "elif tool in ['leiden', 'louvain']:\n",
    "   clustering(adata, n_clusters, radius=radius, method=tool, start=0.1, end=1.1, increment=0.01, refinement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a5bc505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3611, 33538)\n",
      "ARI: 0.5276629246391944\n",
      "NMI: 0.6679098174512333\n",
      "ARI: 0.5276629246391944\n",
      "FMI: 0.6122141166388868\n",
      "Homogeneity: 0.6642825659819916\n",
      "Completeness: 0.6715768989284447\n",
      "V_measure: 0.6679098174512332\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import anndata as ad\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score, homogeneity_score, completeness_score, v_measure_score\n",
    "\n",
    "label_file_path = \"/home/dingsq/dsq/Data/151673/label_data.csv\"\n",
    "label_df = pd.read_csv(label_file_path, sep=',')  # 根据实际情况调整分隔符\n",
    "\n",
    "# 2. 提取标签数据中的 cell_code 和 type 列\n",
    "cell_codes_in_labels = label_df['cell_code'].tolist()  # 标签中的 cell_code\n",
    "label_types = label_df['type'].str.strip().tolist()  # 标签中的 type\n",
    "\n",
    "# 3. 初始化一个字典来存储 cell_code 到 type 的映射\n",
    "label_dict = {cell_code: label_type for cell_code, label_type in zip(cell_codes_in_labels, label_types)}\n",
    "\n",
    "# 4. 遍历 adata 中的每个样本，根据 cell_code 设置 ground_truth\n",
    "#adata.obs['ground_truth'] = None  # 初始化 ground_truth 列\n",
    "\n",
    "for cell_code in label_dict:\n",
    "    if cell_code in adata.obs.index:\n",
    "    # 3. 将 ground_truth 值改为 1\n",
    "        adata.obs.at[cell_code, 'ground_truth'] = label_dict[cell_code]\n",
    "\n",
    "adata = adata[~pd.isnull(adata.obs['ground_truth'])]\n",
    "print(adata.shape)\n",
    "# calculate metric ARI\n",
    "ACC = metrics.accuracy_score(adata.obs['domain'], adata.obs['ground_truth'])\n",
    "NMI = metrics.normalized_mutual_info_score(adata.obs['domain'], adata.obs['ground_truth'])\n",
    "ARI = metrics.adjusted_rand_score(adata.obs['domain'], adata.obs['ground_truth'])\n",
    "FMI = fowlkes_mallows_score(adata.obs['domain'], adata.obs['ground_truth'])\n",
    "homogeneity = homogeneity_score(adata.obs['domain'], adata.obs['ground_truth'])\n",
    "completeness = completeness_score(adata.obs['domain'], adata.obs['ground_truth'])\n",
    "v_measure = v_measure_score(adata.obs['domain'], adata.obs['ground_truth'])\n",
    "print('ARI:', ARI)\n",
    "print('NMI:', NMI)\n",
    "print('ARI:', ARI)\n",
    "print('FMI:', FMI)\n",
    "print('Homogeneity:', homogeneity)\n",
    "print('Completeness:', completeness)\n",
    "print('V_measure:', v_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33897e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=sc.read(\"/home/dingsq/dsq/MGCL-ST-project/Data/151673/sample_data.h5ad\")\n",
    "#Read in hitology image\n",
    "img=cv2.imread(\"/home/dingsq/dsq/MGCL-ST-project/Data/151673/151673_full_image.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e71b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_factor=1000/np.min(img.shape[0:2])\n",
    "resize_width=int(img.shape[1]*resize_factor)\n",
    "resize_height=int(img.shape[0]*resize_factor)\n",
    "counts.var.index=[i.upper() for i in counts.var.index]\n",
    "counts.var_names_make_unique()\n",
    "sc.pp.log1p(counts) # impute on log scale\n",
    "if issparse(counts.X):counts.X=counts.X.A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b82043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Three different algorithms to detect contour, select the best one.Here we use cv2.\n",
    "\n",
    "#-----------------1. Detect contour using cv2-----------------\n",
    "cnt=ST.cv2_detect_contour(img, apertureSize=5,L2gradient = True)\n",
    "\n",
    "binary=np.zeros((img.shape[0:2]), dtype=np.uint8)\n",
    "cv2.drawContours(binary, [cnt], -1, (1), thickness=-1)\n",
    "#Enlarged filter\n",
    "cnt_enlarged = ST.scale_contour(cnt, 1.05)\n",
    "binary_enlarged = np.zeros(img.shape[0:2])\n",
    "cv2.drawContours(binary_enlarged, [cnt_enlarged], -1, (1), thickness=-1)\n",
    "img_new = img.copy()\n",
    "cv2.drawContours(img_new, [cnt], -1, (255), thickness=50)\n",
    "img_new=cv2.resize(img_new, ((resize_width, resize_height)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba31050",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=50\n",
    "# Note, if the numer of superpixels is too large and take too long, you can increase the res to 100\n",
    "enhanced_exp_adata=ST.imputation(img=img, raw=counts, cnt=cnt, genes=counts.var.index.tolist(), shape=\"None\", res=res, s=1, k=2, num_nbs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsq_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
